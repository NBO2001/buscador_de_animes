{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\n",
    "    \"../backend/logging/search.log\", \n",
    "    sep=\";\", \n",
    "    header=None,  \n",
    "    names=['time', 'event', 'query', 'documents']  # Column names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24813/3529901427.py:5: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for name, data in groups:\n"
     ]
    }
   ],
   "source": [
    "groups = df.groupby(by=[\"query\"])\n",
    "\n",
    "with open(\"pre_file.csv\", \"w\") as f2:\n",
    "\n",
    "    for name, data in groups:\n",
    "        vector_lines = list(data.to_numpy())\n",
    "\n",
    "        time, event, query, documents = vector_lines.pop(0)\n",
    "\n",
    "        clicks = []\n",
    "\n",
    "        for time_local, event_local, query_local, documents_local in vector_lines:\n",
    "            \n",
    "            if event_local == \"Search.clicked\":\n",
    "\n",
    "                clicks.append(documents_local)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if len(clicks) != 0:\n",
    "                    documents_local_rank = documents.split(\"|\")\n",
    "                    last = clicks[-1]\n",
    "\n",
    "                    position = documents_local_rank.index(last)\n",
    "                    put_file_documents_local_rank = documents_local_rank[:position+2]\n",
    "\n",
    "                    \n",
    "                    for doc in put_file_documents_local_rank:\n",
    "\n",
    "                        f2.write(f\"{query_local},{doc},1,0\\n\")\n",
    "                    \n",
    "                    for click in clicks:\n",
    "\n",
    "                        f2.write(f\"{query_local},{click},0,1\\n\")\n",
    "\n",
    "                time, event, query, documents = time_local, event_local, query_local, documents_local\n",
    "                \n",
    "                clicks= []\n",
    "\n",
    "        if len(clicks) != 0:\n",
    "            documents_local_rank = documents.split(\"|\")\n",
    "            last = clicks[-1]\n",
    "\n",
    "            position = documents_local_rank.index(last)\n",
    "            put_file_documents_local_rank = documents_local_rank[:position+2]\n",
    "\n",
    "     \n",
    "            \n",
    "            for doc in put_file_documents_local_rank:\n",
    "\n",
    "                f2.write(f\"{query_local},{doc},1,0\\n\")\n",
    "            \n",
    "            for click in clicks:\n",
    "\n",
    "                f2.write(f\"{query_local},{click},0,1\\n\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort -t ',' -k 1n pre_file.csv > pre_file_sorted.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm pre_file.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_file = pd.read_csv(\"pre_file_sorted.csv\", header=None, names=['query', 'document', 'view', 'click'])\n",
    "group_pre_file = df_pre_file.groupby(by=['query','document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_file.csv\", \"w\") as f4:\n",
    "    \n",
    "    for name, df_process in group_pre_file:\n",
    "\n",
    "        views = df_process['view'].sum()\n",
    "        clicks = df_process['click'].sum()\n",
    "\n",
    "        f4.write(f\"{name[0]},{df_process['document'].unique()[0]},{views},{clicks}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"features_file.csv\", \"r\") as f5, open(\"reference_colletion.csv\", \"w\") as f6:\n",
    "\n",
    "    f6.write(f\"query,document,label\\n\")\n",
    "\n",
    "    for line_ in f5.readlines():\n",
    "\n",
    "        list_all = [x.strip() for x in line_.split(\",\")]\n",
    "\n",
    "        click, view, document = list_all.pop(),list_all.pop(),list_all.pop()\n",
    "        query = \" \".join(list_all)\n",
    "\n",
    "        view, click = int(view), int(click)\n",
    "        prior_a = 5\n",
    "        prior_b = 25\n",
    "        posterior_a = click+prior_a\n",
    "        posterior_b = prior_b+(view-click)\n",
    "        label = np.round(((posterior_a  / (posterior_b+posterior_a))*32)).astype(\"int\")\n",
    "\n",
    "        if label > 31:\n",
    "            print(document)\n",
    "            raise ValueError(label)\n",
    "        f6.write(f\"{query},{document},{label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_jobis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
